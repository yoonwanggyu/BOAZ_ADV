{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48910938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538fb4e3",
   "metadata": {},
   "source": [
    "# Agentic RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38891575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 적재된 Pinecone DB에서 데이터 불러오기\n",
    "import os\n",
    "from pinecone import Pinecone\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from dotenv import load_dotenv\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "from typing import Annotated, List, Dict, Any, TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langgraph.prebuilt.tool_node import ToolNode\n",
    "from langchain_core.tools import create_retriever_tool\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "\n",
    "# langsmith 추적\n",
    "load_dotenv()\n",
    "\n",
    "# API키 불러오기\n",
    "open_api_key = os.environ['OPENAI_API_KEY']\n",
    "pinecone_api = os.environ['PINECONE_API_KEY']\n",
    "\n",
    "# OpenAI 임베딩 생성\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-ada-002\",  # OpenAI의 임베딩 모델 사용\n",
    "    api_key=open_api_key)\n",
    "\n",
    "# 인덱스 가져오기\n",
    "pc = Pinecone(api_key=pinecone_api)\n",
    "index_name = \"quickstart\"\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "# PineconeVectorStore를 사용하여 벡터 스토어 생성\n",
    "vectorstore = PineconeVectorStore(index=index, \n",
    "                                  embedding=embeddings, \n",
    "                                  text_key=\"page_content\")\n",
    "\n",
    "# 1) pinecone retriever 설정\n",
    "pinecone_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})\n",
    "\n",
    "# 2) reranker 설정\n",
    "# reranker = HuggingFaceCrossEncoder(model_name=\"BAAI/bge-reranker-v2-m3\")\n",
    "# compressor = CrossEncoderReranker(model=reranker, \n",
    "#                                     top_n=5)\n",
    "# retriever = ContextualCompressionRetriever(base_retriever=pinecone_retriever, \n",
    "#                                           base_compressor=compressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ad97ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Structure:\n",
      "Page Content: - - - - -\n",
      "Metadata: {'author': 'j o u r n a l h o m e p a g e : w w w . e l s e v i e r . c o m', 'category': ['Perioperative', 'PediatricSpecific'], 'id': 194.0, 'page': 7.0, 'paper_title': 'Anaesthesia Critical Care & Pain Medicine', 'source': '1-s2.0-S2352556824000626-main.pdf', 'summary': 'Tranexamic acid reduces blood loss in various surgeries without increasing complications, recommended for orthopedic and cardiac surgeries. Limited data for colorectal surgery.', 'type': 'list', 'year': 2055.0}\n",
      "--------------------------------------------------\n",
      "Document Structure:\n",
      "Page Content: 3.\n",
      "Metadata: {'author': 'a Children’s Hospital, Rotterdam, the Netherlands\\nDepartment of Neonatal and Pediatric Intensive Care, Division of Neonatology, Erasmus MC - Sophia\\nb Children’s Hospital, Rotterdam, the Netherlands\\nDepartment of Anesthesiology, Erasmus MC - Sophia\\nc Children’s Hospital, Rotterdam, the Netherlands\\nDepartment of Pediatric Surgery, Erasmus MC - Sophia', 'category': ['PediatricSpecific', 'Perioperative', 'General'], 'id': 46.0, 'page': 2.0, 'paper_title': 'Judith A. ten Barge, BSc a,*, Alexandra J.M. Zwiers, MD, PhD b, Marijn J. Vermeulen, MD, PhD a,\\nClaudia M.G. Keyzer-Dekker, MD, PhD c, Sinno H.P. Simons, MD, PhD a, Lonneke M. Staals, MD,\\na\\nPhD b, Gerbrich E. van den Bosch, MD, PhD', 'source': '1-s2.0-S0952818024001375-main.pdf', 'summary': 'Anesthesia practices for infants with NEC varied; propofol and sevoflurane were commonly used. Most respondents found care adequate but suggested enhancing monitoring and collaboration.', 'type': 'paragraph', 'year': 2024.0}\n",
      "--------------------------------------------------\n",
      "Document Structure:\n",
      "Page Content: 4.\n",
      "Metadata: {'author': 'f, g,\\na, *, Seema Agarwal b, Bernard Cholley c,d, Jens Fassl e, Michael Griffin\\nAndrew Klein\\nm\\nj, k, Martin Siegemund l, Annewil van Saet\\nTimo Kaakinen h, Patrick Paulus i, Steffen Rex', 'category': ['Drugs', 'Perioperative', 'PediatricSpecific'], 'id': 111.0, 'page': 7.0, 'paper_title': 'A review of European guidelines for patient blood management with a\\nparticular emphasis on antifibrinolytic drug administration for\\ncardiac surgery', 'source': '1-s2.0-S0952818022000101-main.pdf', 'summary': 'UK guidelines on Patient Blood Management (PBM) by NBTC and NHS provide evidence-based recommendations, including TXA use for blood loss reduction. BCSH guidelines cover preoperative anaemia and major bleeding management, recommending TXA for major bleeding after injury. Authors recommend using TXA for bleeding prevention in high-risk cardiac surgery patients. AAGBI guidelines also address blood product use and PBM measures.', 'type': 'paragraph', 'year': 2011.0}\n",
      "--------------------------------------------------\n",
      "Document Structure:\n",
      "Page Content: 3.2.2.\n",
      "Metadata: {'author': 'j o u r n a l h o m e p a g e : w w w . e l s e v i e r . c o m', 'category': ['Perioperative', 'PediatricSpecific'], 'id': 158.0, 'page': 5.0, 'paper_title': 'Anaesthesia Critical Care & Pain Medicine', 'source': '1-s2.0-S2352556824000626-main.pdf', 'summary': 'Inflammation in heart failure patients can lead to functional iron deficiency, affecting iron transport and availability for bone marrow. Diagnosis and treatment may be challenging in certain cases.', 'type': 'paragraph', 'year': 2055.0}\n",
      "--------------------------------------------------\n",
      "Document Structure:\n",
      "Page Content: 6.\n",
      "Metadata: {'author': 'aAnaesthesia and Intensive Care Unit, Azienda Ospedaliera Istituto Ortopedico Gaetano Pini, 20122, Milan, Italy\\nbAnaesthesia and Intensive Care Unit, Policlinico S. Orsola-Malpighi, 40138, Bologna, Italy', 'category': ['Regional', 'Drugs', 'Complications'], 'id': 110.0, 'page': 9.0, 'paper_title': 'Use of direct oral anticoagulants with regional\\nanesthesia in orthopedic patients☆\\nGianluca Cappelleri MD a,⁎, Andrea Fanelli MD b', 'source': '1-s2.0-S0952818016300204-main.pdf', 'summary': 'Assessing neurological function is crucial during anticoagulant therapy, especially with OACs, as standard tests may not detect injury promptly. Monitoring post-procedure is vital due to delayed symptom onset.', 'type': 'paragraph', 'year': 2012.0}\n",
      "--------------------------------------------------\n",
      "Document Structure:\n",
      "Page Content: R.\n",
      "Metadata: {'author': 'Robert van Wilpe, MD, MSc. a, Abraham H. Hulst, MD, PhD a, Sarah.E. Siegelaar, MD, PhD b,\\na\\na, *, Jeroen Hermanides, MD, PhD\\nJ. Hans DeVries, MD, PhD b, Benedikt Preckel, MD, PhD', 'category': ['PediatricSpecific', 'Perioperative', 'Complications'], 'id': 135.0, 'page': 9.0, 'paper_title': 'Type 1 and other types of diabetes mellitus in the perioperative period.\\nWhat the anaesthetist should know', 'source': '1-s2.0-S0952818022003701-main.pdf', 'summary': 'Recommendations and future directions for posttransplantation diabetes mellitus are discussed in various studies, focusing on prevention and treatment strategies.', 'type': 'list', 'year': 2022.0}\n",
      "--------------------------------------------------\n",
      "Document Structure:\n",
      "Page Content: R.\n",
      "Metadata: {'author': 'Robert van Wilpe, MD, MSc. a, Abraham H. Hulst, MD, PhD a, Sarah.E. Siegelaar, MD, PhD b,\\na\\na, *, Jeroen Hermanides, MD, PhD\\nJ. Hans DeVries, MD, PhD b, Benedikt Preckel, MD, PhD', 'category': ['PediatricSpecific', 'Perioperative', 'Complications'], 'id': 90.0, 'page': 5.0, 'paper_title': 'Type 1 and other types of diabetes mellitus in the perioperative period.\\nWhat the anaesthetist should know', 'source': '1-s2.0-S0952818022003701-main.pdf', 'summary': 'No data on perioperative glucose control for MODY subtypes. Suggests withholding sulfonylureas on surgery day to prevent hypoglycemia and using insulin for hyperglycemia.', 'type': 'paragraph', 'year': 2022.0}\n",
      "--------------------------------------------------\n",
      "Document Structure:\n",
      "Page Content: Fig.\n",
      "Metadata: {'author': 'Received November 24, 2017\\nRevised December 11, 2017\\nAccepted December 28, 2017', 'category': ['PediatricSpecific', 'Perioperative', 'Monitoring'], 'id': 26.0, 'page': 2.0, 'paper_title': 'Pediatric lung ultrasound: its role in the\\nperioperative period', 'source': 'APM-13-018.pdf', 'summary': 'Lung ultrasound scan in a 2-year-old boy using a high-frequency linear transducer. Twelve lung regions scanned sequentially from right to left, cranial to caudal, and anterior to posterior.', 'type': 'paragraph', 'year': 2018.0}\n",
      "--------------------------------------------------\n",
      "Document Structure:\n",
      "Page Content: Fig.\n",
      "Metadata: {'author': 'Jeffrey L. Apfelbaum, M.D., Carin A. Hagberg, M.D.,\\nRichard T. Connis, Ph.D., Basem B. Abdelmalak, M.D.,\\nMadhulika Agarkar, M.P.H., Richard P. Dutton, M.D.,\\nJohn E. Fiadjoe, M.D., Robert Greif, M.D.,\\nP . Allan Klock, Jr., M.D., David Mercier, M.D.,\\nSheila N. Myatra, M.D., Ellen P. O’Sullivan, M.D.,\\nWilliam H. Rosenblatt, M.D.,\\nMassimiliano Sorbello, M.D.,\\nAvery Tung, M.D.', 'category': ['Airway', 'PediatricSpecific', 'Intraoperative'], 'id': 517.0, 'page': 26.0, 'paper_title': '2022 American Society\\nof Anesthesiologists\\nPractice Guidelines for\\nManagement of the\\nDifficult Airway*', 'source': '2022 American Society of Anesthesiologists Practice Guidelines for Management of the Difficult Airway.pdf', 'summary': 'The difficult airway algorithm for adult patients emphasizes individualized airway management based on experience, resources, and context. Techniques include awake intubation, invasive airway options, and consideration of supraglottic airways. Alternative approaches for difficult intubation include video-assisted laryngoscopy, different laryngoscope blades, and various adjuncts like introducers and stylets. Options also include postponing intubation or using face mask ventilation.', 'type': 'paragraph', 'year': 2022.0}\n",
      "--------------------------------------------------\n",
      "Document Structure:\n",
      "Page Content: Fig.\n",
      "Metadata: {'author': 'Jeffrey L. Apfelbaum, M.D., Carin A. Hagberg, M.D.,\\nRichard T. Connis, Ph.D., Basem B. Abdelmalak, M.D.,\\nMadhulika Agarkar, M.P.H., Richard P. Dutton, M.D.,\\nJohn E. Fiadjoe, M.D., Robert Greif, M.D.,\\nP . Allan Klock, Jr., M.D., David Mercier, M.D.,\\nSheila N. Myatra, M.D., Ellen P. O’Sullivan, M.D.,\\nWilliam H. Rosenblatt, M.D.,\\nMassimiliano Sorbello, M.D.,\\nAvery Tung, M.D.', 'category': ['Airway', 'PediatricSpecific', 'Intraoperative'], 'id': 544.0, 'page': 30.0, 'paper_title': '2022 American Society\\nof Anesthesiologists\\nPractice Guidelines for\\nManagement of the\\nDifficult Airway*', 'source': '2022 American Society of Anesthesiologists Practice Guidelines for Management of the Difficult Airway.pdf', 'summary': 'Pediatric difficult airway infographic emphasizes team-based approach, equipment readiness, and color-coded oxygenation/ventilation assessment for effective management. For challenging intubations, use familiar techniques/devices like supraglottic airway or videolaryngoscopy. Limit attempts and reassess ventilation regularly. In challenging intubation cases, address functional and anatomical obstructions. Use various techniques and consider debriefing the team for improvement and support.', 'type': 'paragraph', 'year': 2022.0}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Pinecone 문서 구조 확인\n",
    "sample_docs = pinecone_retriever.invoke(\"test query\")  # 임의의 테스트 쿼리로 문서 검색\n",
    "for doc in sample_docs:\n",
    "    print(\"Document Structure:\")\n",
    "    print(\"Page Content:\", doc.page_content)\n",
    "    print(\"Metadata:\", doc.metadata)\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f33325e",
   "metadata": {},
   "source": [
    "## Tool 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a45f8c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import create_retriever_tool\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    pinecone_retriever,\n",
    "    name=\"pediatric_guideline_tool\",\n",
    "    description=\"Retrieve information from pediatric anesthesia guideline documents stored in Pinecone.\",\n",
    "    document_prompt=PromptTemplate.from_template(\n",
    "        \"<document>\\n<context>{page_content}</context>\\n<metadata><source>{source}</source><page>{page}</page><category>{category}</category><year>{year}</year><summary>{summary}</summary></metadata>\\n</document>\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50156d7b",
   "metadata": {},
   "source": [
    "## State 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "303f2caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 0. 상태 정의 ---\n",
    "class AgenticState(TypedDict):\n",
    "    question: Annotated[str, \"User question\"]\n",
    "    memory_hit: bool\n",
    "    answers: Annotated[List[str], \"Generated answers\"]\n",
    "    clarified_question: str\n",
    "    clarification_needed: bool\n",
    "    subqueries: Annotated[List[str], \"Decomposed sub-queries\"]\n",
    "    retrieval_needed: bool\n",
    "    documents: Annotated[List[Dict], \"Retrieved documents\"]\n",
    "    memory: Annotated[List[Dict[str, str]], \"Memory store\"]\n",
    "    meta_filter: Dict[str, Any]\n",
    "    tool_calls: Annotated[List[Dict], \"Tool calls\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d68832d",
   "metadata": {},
   "source": [
    "# Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4703bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. agent Node ---\n",
    "# Agentic RAG의 시작점으로, LLM이 질문을 분석해 도구 호출(retriever_tool) 여부를 결정.\n",
    "# bind_functions로 도구를 바인딩하고, function_call을 통해 도구 호출 여부를 확인.\n",
    "# 도구가 필요하면 tool_calls와 retrieval_needed를 설정, 그렇지 않으면 직접 답변 생성.\n",
    "\n",
    "def agent_node(state: AgenticState):\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(tools=[retriever_tool])  # bind_functions -> bind_tools\n",
    "    question = state.get(\"clarified_question\") or state[\"question\"]\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are an expert in pediatric anesthesia. Analyze the question and either call a tool or generate an answer directly.\"),\n",
    "        (\"human\", \"{question}\")\n",
    "    ]).format(question=question)\n",
    "    response = llm.invoke(prompt)\n",
    "    tool_calls = response.additional_kwargs.get(\"tool_calls\", []) if hasattr(response, \"additional_kwargs\") else []\n",
    "    if tool_calls:\n",
    "        return {\"tool_calls\": tool_calls, \"retrieval_needed\": True}  # 모든 tool_calls 반환\n",
    "    return {\"answers\": [response.content], \"retrieval_needed\": False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e814b266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Node Result: {'tool_calls': [{'id': 'call_X3jfl076yA1sCWXAYuZs0fZu', 'function': {'arguments': '{\"query\":\"risk of VTE in pediatric anesthesia\"}', 'name': 'pediatric_guideline_tool'}, 'type': 'function'}], 'retrieval_needed': True}\n",
      "Tool Calls Detected: [{'id': 'call_X3jfl076yA1sCWXAYuZs0fZu', 'function': {'arguments': '{\"query\":\"risk of VTE in pediatric anesthesia\"}', 'name': 'pediatric_guideline_tool'}, 'type': 'function'}]\n",
      "Query in Tool Call: risk of VTE in pediatric anesthesia\n",
      "Retrieval Needed: True\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# agent_node 테스트 (수정)\n",
    "def test_agent_node():\n",
    "    # 테스트용 상태\n",
    "    test_state = {\"question\": \"What is the risk of VTE?\", \"memory\": []}\n",
    "    \n",
    "    # agent_node 실행\n",
    "    result = agent_node(test_state)\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(\"Agent Node Result:\", result)\n",
    "    if \"tool_calls\" in result:\n",
    "        print(\"Tool Calls Detected:\", result[\"tool_calls\"])\n",
    "        # tool_calls 내부 구조에 따라 쿼리 추출\n",
    "        if result[\"tool_calls\"]:\n",
    "            tool_call = result[\"tool_calls\"][0]\n",
    "            if \"function\" in tool_call and \"arguments\" in tool_call[\"function\"]:\n",
    "                arguments_str = tool_call[\"function\"][\"arguments\"]\n",
    "                try:\n",
    "                    arguments = json.loads(arguments_str)  # JSON 파싱\n",
    "                    query = arguments.get(\"query\", \"No query found\")\n",
    "                    print(\"Query in Tool Call:\", query)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(\"Failed to parse arguments:\", arguments_str)\n",
    "            else:\n",
    "                print(\"Query not found in expected structure. Tool Call Details:\", tool_call)\n",
    "        print(\"Retrieval Needed:\", result[\"retrieval_needed\"])\n",
    "    else:\n",
    "        print(\"Direct Answer Generated:\", result[\"answers\"])\n",
    "        print(\"Retrieval Needed:\", result[\"retrieval_needed\"])\n",
    "\n",
    "# 테스트 실행\n",
    "test_agent_node()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a53a8bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check Memory Result: {'memory_hit': False, 'similarity_score': 0.073943645}\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Memory Lookup Node ---\n",
    "# 이전에 동일하거나 유사한 질문에 대한 답변이 메모리에 있는지 확인. NLP로 유사도 계산.\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 임베딩 모델 초기화\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def check_memory(state: AgenticState):\n",
    "    question = state[\"question\"]\n",
    "    memory = state.get(\"memory\", [])\n",
    "    \n",
    "    # 메모리가 비어 있으면 바로 종료\n",
    "    if not memory:\n",
    "        return {\"memory_hit\": False}\n",
    "    \n",
    "    # 질문 임베딩 생성\n",
    "    question_embedding = embedding_model.encode(question, convert_to_tensor=True)\n",
    "    \n",
    "    # 메모리 항목 임베딩 생성 및 유사도 계산\n",
    "    max_similarity = 0.0\n",
    "    best_match = None\n",
    "    for entry in memory:\n",
    "        memory_embedding = embedding_model.encode(entry[\"question\"], convert_to_tensor=True)\n",
    "        similarity = cosine_similarity(question_embedding.reshape(1, -1), memory_embedding.reshape(1, -1))[0][0]\n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            best_match = entry\n",
    "    \n",
    "    # 유사도 임계값 (0.85 이상이면 유사 질문으로 간주)\n",
    "    threshold = 0.85\n",
    "    if max_similarity >= threshold and best_match:\n",
    "        return {\"answers\": [best_match[\"answer\"]], \"memory_hit\": True, \"similarity_score\": max_similarity}\n",
    "    return {\"memory_hit\": False, \"similarity_score\": max_similarity}\n",
    "\n",
    "# 테스트\n",
    "test_state = {\"question\": \"What is the risk of VTE?\", \"memory\": [{\"question\": \"소아마취 시 프로포폴과 케타민 사용 시 주의점\", \"answer\": \"호흡억제 주의 필요\"}]}\n",
    "result = check_memory(test_state)\n",
    "print(\"Check Memory Result:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd33ceb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Clarification Node (질문이 불명확하면 사용자 입력 요청) ---\n",
    "# 질문이 명확한지 판단하고, 명확하지 않으면 추가 정보를 요청.\n",
    "\n",
    "def clarification(state: AgenticState):\n",
    "    question = state.get(\"clarified_question\") or state[\"question\"]\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "    clarify_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are an expert in pediatric anesthesia. Determine if the user's question is clear and specific.\"),\n",
    "        (\"human\", \"Question: '{question}'\\nIs this question clear and specific? Respond with 'yes' or 'no' only.\")\n",
    "    ]).format(question=question)\n",
    "    res = llm.invoke(clarify_prompt).content.strip().lower()\n",
    "    if res == \"no\":\n",
    "        clar_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"Provide a concise request for additional information to clarify the question.\"),\n",
    "            (\"human\", \"Question: '{question}'\\nWhat additional information is needed? Respond in one sentence.\")\n",
    "        ]).format(question=question)\n",
    "        clar_msg = llm.invoke(clar_prompt).content.strip()\n",
    "        return {\"clarification_needed\": True, \"clarify_msg\": clar_msg}\n",
    "    return {\"clarification_needed\": False, \"clarified_question\": question}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f4c7411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Clarification Response Node (사용자 추가 입력 받아서 state에 반영) ---\n",
    "### 수정해야함.\n",
    "def clarification_response(state: AgenticState):\n",
    "    # 실제 프론트/채팅 인터페이스라면 사용자 입력을 받는 자리!\n",
    "    # 여기선 예시로 그냥 state[\"clarified_question\"]을 그대로 사용하거나,\n",
    "    # 실제 상황에서는 input() 등으로 받아서 업데이트 가능.\n",
    "    clarified = state.get(\"clarified_question\") or state[\"question\"]\n",
    "    return {\"clarified_question\": clarified}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3712a87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Additional information required? (LLM만으로 답변 가능?) ---\n",
    "def answerable_by_llm(state: AgenticState):\n",
    "    question = state.get(\"clarified_question\") or state[\"question\"]\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are an expert in pediatric anesthesia. Determine if external document retrieval is needed.\"),\n",
    "        (\"human\", \"Can you answer this question with high confidence without external documents?\\nQuestion: {question}\\nRespond with 'yes' or 'no' only.\")\n",
    "    ]).format(question=question)\n",
    "    res = llm.invoke(prompt).content.strip().lower()\n",
    "    return {\"retrieval_needed\": res == \"no\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5679fa71",
   "metadata": {},
   "source": [
    "* 수정해야함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eebc4431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. Query Routing Node (메타필터/도구선택 분리) ---\n",
    "### 수정해야함.\n",
    "def query_routing(state: AgenticState):\n",
    "    question = state.get(\"clarified_question\") or state[\"question\"]\n",
    "    meta_filter = {}\n",
    "    if any(keyword in question.lower() for keyword in [\"drug\", \"약물\", \"medication\"]):\n",
    "        meta_filter[\"metadata\"] = {\"category\": \"drug\"}\n",
    "    elif any(keyword in question.lower() for keyword in [\"recent\", \"최신\", \"최근\"]):\n",
    "        meta_filter[\"metadata\"] = {\"year\": \">=2020\"}\n",
    "    return {\"meta_filter\": meta_filter}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6de25618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7. Sub-query 분해 노드 ---\n",
    "def decompose_query(state: AgenticState):\n",
    "    question = state.get(\"clarified_question\") or state[\"question\"]\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Decompose the question into LLM-friendly sub-queries, one per line. If not a compound question, return the original question.\"),\n",
    "        (\"human\", \"Question: {question}\")\n",
    "    ]).format(question=question)\n",
    "    response = llm.invoke(prompt).content.strip().split('\\n')\n",
    "    subqueries = [q.strip() for q in response if q.strip()]\n",
    "    return {\"subqueries\": subqueries}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0166bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 8. Retrieval Node (ToolNode) ---\n",
    "retriever_tool_node = ToolNode(tools=[retriever_tool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "813d93f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  --- 9. 문서 relevance 체크 노드 ---\n",
    "def check_relevance(state: AgenticState):\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "    docs = state.get(\"documents\", [])\n",
    "    subqueries = state[\"subqueries\"]\n",
    "    for doc, subquery in zip(docs, subqueries):\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"You are an expert in pediatric anesthesia. Assess document relevance.\"),\n",
    "            (\"human\", \"Document: {doc}\\nQuestion: {subquery}\\nIs this document relevant to the question? Respond with 'yes' or 'no' only.\")\n",
    "        ]).format(doc=doc[\"page_content\"], subquery=subquery)\n",
    "        res = llm.invoke(prompt).content.strip().lower()\n",
    "        if res != \"yes\":\n",
    "            return \"retry\"\n",
    "    return \"proceed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3340308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 10. 답변 생성 노드 ---\n",
    "def generate_answer(state: AgenticState):\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "    answers = []\n",
    "    subqueries = state.get(\"subqueries\", [state[\"question\"]])\n",
    "    docs = state.get(\"documents\", [{\"page_content\": \"\"}] * len(subqueries))\n",
    "    context = \"\\n\\n\".join([doc[\"page_content\"] for doc in docs])\n",
    "    for q, doc in zip(subqueries, docs):\n",
    "        source = doc.get(\"metadata\", {}).get(\"source\", \"unknown_document\")\n",
    "        page = doc.get(\"metadata\", {}).get(\"page\", \"unknown\")\n",
    "        prompt = PromptTemplate.from_template(\n",
    "            \"\"\"You are an assistant specialized in question-answering tasks based on medical research papers.\n",
    "Use the following pieces of retrieved context to answer the question. If you don't know the answer, simply say that you don't know.\n",
    "Answer in Korean.\n",
    "\n",
    "# Direction:\n",
    "1. Understand the intent of the question and provide the most accurate answer.\n",
    "2. Identify and select the most relevant content from the retrieved context that directly relates to the question.\n",
    "3. Construct a concise and logical answer by rearranging the selected information into coherent paragraphs.\n",
    "4. If there is no relevant context for the question, state: \"I can't find an answer to that question in the materials I have.\"\n",
    "5. Present your answer in a table of key points where applicable.\n",
    "6. Include all sources and their corresponding whole page numbers in your answer.\n",
    "7. Write your answer entirely in Korean.\n",
    "8. Be as detailed as possible in your answer.\n",
    "9. Begin your answer with \"This answer is based on content found in the document **📚\" and end with \"**📌 [document_name]\" — here, [document_name] should be replaced with the document_name from the metadata.\n",
    "10. Page numbers should be whole numbers.\n",
    "\n",
    "#Context: \n",
    "{context}\n",
    "\n",
    "###\n",
    "\n",
    "#Example Format:\n",
    "**📚 문서에서 검색한 내용 기반 답변입니다**\n",
    "\n",
    "(Detailed answer to the question)\n",
    "\n",
    "**📌 출처**\n",
    "- document_name, 192쪽\n",
    "- document_name, 192쪽\n",
    "- ...\n",
    "\n",
    "###\n",
    "\n",
    "#Question:\n",
    "{q}\n",
    "\n",
    "#Answer:\"\"\"\n",
    "        )\n",
    "        ans = llm.invoke(prompt.format(context=context, q=q)).content.strip()\n",
    "        # Add source if answer is valid\n",
    "        if \"I can't find an answer\" not in ans and \"모름\" not in ans:\n",
    "            ans += f\"\\n\\n**📌 출처**\\n- {source}, {page}쪽\"\n",
    "        answers.append(ans)\n",
    "    return {\"answers\": answers}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abe52138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 11. 답변 검토 노드 ---\n",
    "def review_answer(state: AgenticState):\n",
    "    for a in state[\"answers\"]:\n",
    "        if len(a) < 20 or \"모름\" in a or \"I can't find an answer\" in a:\n",
    "            return \"regen\"\n",
    "    return \"accept\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34545fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 12. Memory update ---\n",
    "def update_memory(state: AgenticState):\n",
    "    mem = state.get(\"memory\", [])\n",
    "    question = state.get(\"clarified_question\") or state[\"question\"]\n",
    "    answer = \"\\n\".join(state[\"answers\"])\n",
    "    if len(mem) > 10:  # Limit memory size\n",
    "        mem.pop(0)\n",
    "    mem.append({\"question\": question, \"answer\": answer})\n",
    "    return {\"memory\": mem}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51469410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 13. Format response ---\n",
    "def format_response(state: AgenticState):\n",
    "    return {\"response\": \"\\n\\n\".join(state[\"answers\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e817bab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1c5e24f61e0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 14. LangGraph StateGraph 연결 ---\n",
    "builder = StateGraph(AgenticState)\n",
    "builder.add_node(\"agent\", agent_node)\n",
    "builder.add_node(\"check_memory\", check_memory)\n",
    "builder.add_node(\"clarification\", clarification)\n",
    "builder.add_node(\"answerable_by_llm\", answerable_by_llm)\n",
    "builder.add_node(\"query_routing\", query_routing)\n",
    "builder.add_node(\"decompose_query\", decompose_query)\n",
    "builder.add_node(\"retrieve_docs\", retriever_tool_node)\n",
    "builder.add_node(\"check_relevance\", check_relevance)\n",
    "builder.add_node(\"generate_answer\", generate_answer)\n",
    "builder.add_node(\"review_answer\", review_answer)\n",
    "builder.add_node(\"update_memory\", update_memory)\n",
    "builder.add_node(\"format_response\", format_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e08352",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "At 'clarification' node, 'condition' branch found unknown target 'clarification_response'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m builder.add_edge(\u001b[33m\"\u001b[39m\u001b[33mupdate_memory\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mformat_response\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m builder.add_edge(\u001b[33m\"\u001b[39m\u001b[33mformat_response\u001b[39m\u001b[33m\"\u001b[39m, END)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m app = \u001b[43mbuilder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\chatbot\\Lib\\site-packages\\langgraph\\graph\\state.py:612\u001b[39m, in \u001b[36mStateGraph.compile\u001b[39m\u001b[34m(self, checkpointer, cache, store, interrupt_before, interrupt_after, debug, name)\u001b[39m\n\u001b[32m    609\u001b[39m interrupt_after = interrupt_after \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[32m    611\u001b[39m \u001b[38;5;66;03m# validate the graph\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m612\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    613\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    614\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m*\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\n\u001b[32m    615\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m*\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    616\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    617\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    618\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    620\u001b[39m \u001b[38;5;66;03m# prepare output channels\u001b[39;00m\n\u001b[32m    621\u001b[39m output_channels = (\n\u001b[32m    622\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m__root__\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.schemas[\u001b[38;5;28mself\u001b[39m.output]) == \u001b[32m1\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    629\u001b[39m     ]\n\u001b[32m    630\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\chatbot\\Lib\\site-packages\\langgraph\\graph\\graph.py:290\u001b[39m, in \u001b[36mGraph.validate\u001b[39m\u001b[34m(self, interrupt)\u001b[39m\n\u001b[32m    288\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m end \u001b[38;5;129;01min\u001b[39;00m branch.ends.values():\n\u001b[32m    289\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.nodes \u001b[38;5;129;01mand\u001b[39;00m end != END:\n\u001b[32m--> \u001b[39m\u001b[32m290\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    291\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAt \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m node, \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcond\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m branch found unknown target \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    292\u001b[39m             )\n\u001b[32m    293\u001b[39m         all_targets.add(end)\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: At 'clarification' node, 'condition' branch found unknown target 'clarification_response'"
     ]
    }
   ],
   "source": [
    "# Edges\n",
    "builder.set_entry_point(\"agent\")\n",
    "builder.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    lambda s: \"tool\" if s.get(\"tool_calls\") else \"memory\",\n",
    "    {\"tool\": \"retrieve_docs\", \"memory\": \"check_memory\"}\n",
    ")\n",
    "builder.add_conditional_edges(\n",
    "    \"check_memory\",\n",
    "    lambda s: \"hit\" if s[\"memory_hit\"] else \"miss\",\n",
    "    {\"hit\": \"format_response\", \"miss\": \"clarification\"}\n",
    ")\n",
    "builder.add_conditional_edges(\n",
    "    \"clarification\",\n",
    "    lambda s: \"clarify\" if s[\"clarification_needed\"] else \"ok\",\n",
    "    {\"clarify\": \"clarification_response\", \"ok\": \"answerable_by_llm\"}\n",
    ")\n",
    "builder.add_conditional_edges(\n",
    "    \"answerable_by_llm\",\n",
    "    lambda s: \"direct\" if not s[\"retrieval_needed\"] else \"retrieval\",\n",
    "    {\"direct\": \"generate_answer\", \"retrieval\": \"query_routing\"}\n",
    ")\n",
    "builder.add_edge(\"query_routing\", \"decompose_query\")\n",
    "builder.add_edge(\"decompose_query\", \"retrieve_docs\")\n",
    "builder.add_conditional_edges(\n",
    "    \"retrieve_docs\",\n",
    "    lambda s: check_relevance(s),\n",
    "    {\"proceed\": \"generate_answer\", \"retry\": \"decompose_query\"}\n",
    ")\n",
    "builder.add_edge(\"generate_answer\", \"review_answer\")\n",
    "builder.add_conditional_edges(\n",
    "    \"review_answer\",\n",
    "    lambda s: \"accept\" if all(len(a) > 20 and \"모름\" not in a and \"I can't find an answer\" not in a for a in s[\"answers\"]) else \"regen\",\n",
    "    {\"accept\": \"update_memory\", \"regen\": \"generate_answer\"}\n",
    ")\n",
    "builder.add_edge(\"update_memory\", \"format_response\")\n",
    "builder.add_edge(\"format_response\", END)\n",
    "\n",
    "app = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6baa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    state = {\"question\": \"소아마취 시 프로포폴과 케타민의 병용 주의사항은?\", \"memory\": []}\n",
    "    for step in app.stream(state):\n",
    "        print(step)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (chatbot)",
   "language": "python",
   "name": "chatbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
