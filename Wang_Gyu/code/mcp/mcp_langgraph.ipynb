{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ÏµúÏ¢Ö Flow ÎßåÎì§Ïñ¥ Í∞ÄÎäî Ï§ë....\n",
    "\n",
    "- Íµ¨ÏÑ± ÎÖ∏Îìú : Vector DB / Neo4j DB / Slack\n",
    "- ÎÖ∏Îìú ÏÑ†ÌÉù Ïó¨Î∂Ä : GPT Function Calling\n",
    "- Í≤ÄÏÉâÏùÑ ÏúÑÌïú ÏßàÎ¨∏ Ïû¨ÏÉùÏÑ± : DeepRetrieval-PubMed-3B\n",
    "- Í≤ÄÏÉâ Î¨∏ÏÑú ÌèâÍ∞Ä : LLM as a Judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neo4j_retriever': StructuredTool(name='neo4j_retriever', description='\\n    ÏûêÏó∞Ïñ¥ ÏßàÎ¨∏ÏùÑ ÏûÑÎ≤†Îî©ÌïòÏó¨ (:Patient.embedding) Î≤°ÌÑ∞ Ïù∏Îç±Ïä§ÏôÄ ÏΩîÏÇ¨Ïù∏ Ïú†ÏÇ¨ÎèÑ Top-k ÌôòÏûêÎ•º Î∞òÌôò.\\n    ', args_schema={'properties': {'question': {'title': 'Question', 'type': 'string'}, 'top_k': {'default': 3, 'title': 'Top K', 'type': 'integer'}}, 'required': ['question'], 'title': 'neo4j_retrieverArguments', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x30f344900>), 'VectorDB_retriever': StructuredTool(name='VectorDB_retriever', args_schema={'properties': {'query': {'title': 'Query', 'type': 'string'}}, 'required': ['query'], 'title': 'VectorDB_retrieverArguments', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x30f3823e0>), 'slack_list_channels': StructuredTool(name='slack_list_channels', description='List public or pre-defined channels in the workspace with pagination', args_schema={'type': 'object', 'properties': {'limit': {'type': 'number', 'description': 'Maximum number of channels to return (default 100, max 200)', 'default': 100}, 'cursor': {'type': 'string', 'description': 'Pagination cursor for next page of results'}}}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x30f382f20>), 'slack_post_message': StructuredTool(name='slack_post_message', description='Post a new message to a Slack channel', args_schema={'type': 'object', 'properties': {'channel_id': {'type': 'string', 'description': 'The ID of the channel to post to'}, 'text': {'type': 'string', 'description': 'The message text to post'}}, 'required': ['channel_id', 'text']}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x30f3827a0>), 'slack_reply_to_thread': StructuredTool(name='slack_reply_to_thread', description='Reply to a specific message thread in Slack', args_schema={'type': 'object', 'properties': {'channel_id': {'type': 'string', 'description': 'The ID of the channel containing the thread'}, 'thread_ts': {'type': 'string', 'description': \"The timestamp of the parent message in the format '1234567890.123456'. Timestamps in the format without the period can be converted by adding the period such that 6 numbers come after it.\"}, 'text': {'type': 'string', 'description': 'The reply text'}}, 'required': ['channel_id', 'thread_ts', 'text']}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x30f382e80>), 'slack_add_reaction': StructuredTool(name='slack_add_reaction', description='Add a reaction emoji to a message', args_schema={'type': 'object', 'properties': {'channel_id': {'type': 'string', 'description': 'The ID of the channel containing the message'}, 'timestamp': {'type': 'string', 'description': 'The timestamp of the message to react to'}, 'reaction': {'type': 'string', 'description': 'The name of the emoji reaction (without ::)'}}, 'required': ['channel_id', 'timestamp', 'reaction']}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x30f383880>), 'slack_get_channel_history': StructuredTool(name='slack_get_channel_history', description='Get recent messages from a channel', args_schema={'type': 'object', 'properties': {'channel_id': {'type': 'string', 'description': 'The ID of the channel'}, 'limit': {'type': 'number', 'description': 'Number of messages to retrieve (default 10)', 'default': 10}}, 'required': ['channel_id']}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x30f383420>), 'slack_get_thread_replies': StructuredTool(name='slack_get_thread_replies', description='Get all replies in a message thread', args_schema={'type': 'object', 'properties': {'channel_id': {'type': 'string', 'description': 'The ID of the channel containing the thread'}, 'thread_ts': {'type': 'string', 'description': \"The timestamp of the parent message in the format '1234567890.123456'. Timestamps in the format without the period can be converted by adding the period such that 6 numbers come after it.\"}}, 'required': ['channel_id', 'thread_ts']}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x30f382520>), 'slack_get_users': StructuredTool(name='slack_get_users', description='Get a list of all users in the workspace with their basic profile information', args_schema={'type': 'object', 'properties': {'cursor': {'type': 'string', 'description': 'Pagination cursor for next page of results'}, 'limit': {'type': 'number', 'description': 'Maximum number of users to return (default 100, max 200)', 'default': 100}}}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x30f383920>), 'slack_get_user_profile': StructuredTool(name='slack_get_user_profile', description='Get detailed profile information for a specific user', args_schema={'type': 'object', 'properties': {'user_id': {'type': 'string', 'description': 'The ID of the user'}}, 'required': ['user_id']}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x30f3836a0>)}\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated, List, TypedDict, Dict\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_community.document_transformers import LongContextReorder\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.messages import AIMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from openai import OpenAI\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "# device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# ÏÇ¨Ïö© Î™®Îç∏Îì§\n",
    "model_client = OpenAI()\n",
    "model = ChatOpenAI(temperature=0.2,\n",
    "                    model_name=\"gpt-4o\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"DeepRetrieval/DeepRetrieval-PubMed-3B\", trust_remote_code=True)\n",
    "# deepretrieval_model = AutoModelForCausalLM.from_pretrained(\"DeepRetrieval/DeepRetrieval-PubMed-3B\", trust_remote_code=True)\n",
    "# deepretrieval_model.to(device)\n",
    "\n",
    "# langgraph state Ï†ïÏùò\n",
    "class ChatbotState(TypedDict):\n",
    "    question: Annotated[str, \"Question\"]  \n",
    "    decision_slack: Annotated[str, \"Decision_slack\"]\n",
    "    tools: Annotated[List, \"Tools\"]\n",
    "    tools_query: Annotated[List, \"Tools_Query\"]\n",
    "    # regenerated_question: Annotated[str, \"Regenerated Question\"]\n",
    "    neo4j_documents: Annotated[List, \"Neo4j_Documents\"]  \n",
    "    vector_documents : Annotated[List,\"Vector_Documents\"]\n",
    "    final_answer: Annotated[str, \"Final_Answer\"]  \n",
    "    slack_response: Annotated[str, \"Slack_Response\"]\n",
    "    messages: Annotated[List, add_messages] \n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "# MCP ÏÑúÎ≤ÑÎì§ Î∂àÎü¨Ïò§Í∏∞\n",
    "mcp_client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"neo4j_retriever\": {\n",
    "            \"command\": \"/opt/anaconda3/envs/boaz/bin/python\",\n",
    "            \"args\": [\"mcp_neo4j_server.py\"],\n",
    "            \"transport\": \"stdio\",\n",
    "        },\n",
    "        \"VectorDB_retriever\": {\n",
    "            \"command\": \"/opt/anaconda3/envs/boaz/bin/python\",\n",
    "            \"args\": [\"mcp_vectordb_server.py\"],\n",
    "            \"transport\": \"stdio\",\n",
    "        },\n",
    "        # Slack MCP ÏÑúÎ≤Ñ ÏÑ§Ï†ï\n",
    "        \"slack\": {\n",
    "            \"command\": \"npx\",\n",
    "            \"args\": [\n",
    "                \"-y\",\n",
    "                \"@modelcontextprotocol/server-slack\"\n",
    "            ],\n",
    "            \"transport\": \"stdio\", \n",
    "            \"env\": {\n",
    "                \"SLACK_BOT_TOKEN\": os.getenv(\"SLACK_BOT_TOKEN\"),\n",
    "                \"SLACK_TEAM_ID\": os.getenv(\"SLACK_TEAM_ID\"),\n",
    "                # ÏÑ†ÌÉùÏÇ¨Ìï≠: ÌäπÏ†ï Ï±ÑÎÑêÎßå Ï†ëÍ∑ºÌïòÎ†§Îäî Í≤ΩÏö∞\n",
    "                \"SLACK_CHANNEL_IDS\": \"C093H2LTEF4\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# MCP ÏÑúÎ≤Ñ Ïûò Í∞ÄÏ†∏ÏôîÎäîÏßÄ ÌôïÏù∏\n",
    "mcp_tools = await mcp_client.get_tools()\n",
    "tools_dict = {tool.name: tool for tool in mcp_tools}\n",
    "print(tools_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "# from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# mcp_client = MultiServerMCPClient(\n",
    "#     {\n",
    "#         # Ïò¨Î∞îÎ•∏ Slack MCP ÏÑúÎ≤Ñ ÏÑ§Ï†ï\n",
    "#         \"slack\": {\n",
    "#             \"command\": \"npx\",\n",
    "#             \"args\": [\n",
    "#                 \"-y\",\n",
    "#                 \"@modelcontextprotocol/server-slack\"\n",
    "#             ],\n",
    "#             \"transport\": \"stdio\",  # transport Ï∂îÍ∞Ä ÌïÑÏöî\n",
    "#             \"env\": {\n",
    "#                 \"SLACK_BOT_TOKEN\": \n",
    "#                 \"SLACK_TEAM_ID\": \n",
    "#                 # ÏÑ†ÌÉùÏÇ¨Ìï≠: ÌäπÏ†ï Ï±ÑÎÑêÎßå Ï†ëÍ∑ºÌïòÎ†§Îäî Í≤ΩÏö∞\n",
    "#                 # \"SLACK_CHANNEL_IDS\": \n",
    "#             }\n",
    "#         }\n",
    "#     }\n",
    "# )\n",
    "\n",
    "\n",
    "# tools = await mcp_client.get_tools()\n",
    "\n",
    "# # OpenAI Î™®Îç∏ ÏÑ§Ï†ï\n",
    "# model_client = OpenAI()\n",
    "\n",
    "# model = ChatOpenAI(temperature=0.2,\n",
    "#                       model_name=\"gpt-4o\")\n",
    "\n",
    "# # ÏóêÏù¥Ï†ÑÌä∏ ÏÉùÏÑ±\n",
    "# agent = create_react_agent(model, tools)\n",
    "\n",
    "# # ÏóêÏù¥Ï†ÑÌä∏ÏóêÍ≤å ÏûêÏó∞Ïñ¥Î°ú ÏßÄÏãú -> Ï±ÑÎÑêÎ™Ö ÏßÄÏ†ï ÌïÑÏöî\n",
    "# response = await agent.ainvoke({\n",
    "#     \"messages\": [{\n",
    "#         \"role\": \"user\",\n",
    "#         \"content\": (\n",
    "#             \"Î∞±ÏßÄÏó∞Ïùò Îã§Ïù¥Î†âÌä∏ Î©îÏãú\"\n",
    "#             \"slack_post_message Ìà¥ÏùÑ ÏÇ¨Ïö©Ìï¥.\"\n",
    "#         )\n",
    "#     }]\n",
    "# })\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_calling_tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"name\": \"neo4j_retriever\",\n",
    "        \"description\": \"\"\"Use this tool when the user's query is explicitly about patient-specific \n",
    "            clinical information or refers to structured medical records.\n",
    "\n",
    "            This includes queries containing terms such as: \n",
    "            'ÌôòÏûê', 'ÌôòÏûêÏ†ïÎ≥¥', 'ÌôòÏûêÍ∏∞Î°ù', 'ÌôòÏûêÏù¥Î†•', 'ÌôòÏûêÎç∞Ïù¥ÌÑ∞', 'ÌôòÏûêÏÉÅÌÉú', \n",
    "            'ÏàòÏà†Ïù¥Î†•', 'Í≤ÄÏÇ¨Í∏∞Î°ù', 'ÏßÑÎ£åÍ∏∞Î°ù', 'ÏûÖÏõê', 'Ìá¥Ïõê', 'Î≥µÏö©ÏïΩÎ¨º',\n",
    "            'ÏßÑÎã®', 'ÏàòÏà†Î™Ö', 'ÎßàÏ∑®Ï†ú', 'ÎßàÏ∑®Ï†ú Ïú†Ìòï', 'ÏàòÏà† Ï†Ñ ÏÉÅÌÉú', 'ÏàòÏà† ÌõÑ ÏÉÅÌÉú'.\n",
    "\n",
    "            These queries typically require retrieving structured data from graph-based \n",
    "            medical records (e.g., Neo4j) related to an individual patient or to specific \n",
    "            clinical procedures.\n",
    "\n",
    "            This tool is designed to access and return relevant information such as:\n",
    "            surgery history, diagnoses, anesthesia types used, pre- and post-operative conditions, \n",
    "            medication usage, lab results, and hospitalization records.\n",
    "\n",
    "            Use this tool when the question involves:\n",
    "            - Specific patients\n",
    "            - Specific treatments or surgeries\n",
    "            - Named diagnoses or procedures\n",
    "            - Clinical state before/after operations\n",
    "\n",
    "            Do not use this tool for general medical knowledge, non-clinical topics, or \n",
    "            queries unrelated to structured or relational patient data.\"\"\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"\"\"Please write the query as a natural language question about the patient's clinical records.\n",
    "\n",
    "                    The query will be interpreted to explore nodes (e.g., Surgery, Anesthesia, Diagnosis, Patient) and their relationships (e.g., surgeries received by a specific patient) in a graph database.\n",
    "\n",
    "                    For example, the question \"Tell me the name of the most recent surgery and the anesthesia used\" will be processed as a query exploring connections between Surgery and Anesthesia nodes.\n",
    "\n",
    "                    Also, the question \"Tell me the pre-operative condition and diagnosis of patient Hong Gil-dong\" will be interpreted as a query that finds the Person node with the name 'Hong Gil-dong' and extracts the related Pre-op condition and Diagnosis nodes.\n",
    "\n",
    "                    If a patient name is specified, please write the query to retrieve not only that patient but also other patients with similar symptoms.\n",
    "\n",
    "                    If no patient name is given, please write the query to search for patients matching the symptoms, surgery names, or diagnoses mentioned in the question.\n",
    "\n",
    "                    The more specific the patient information or clinical conditions included, the more accurately the relevant data can be retrieved.\"\"\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"query\"],\n",
    "            \"additionalProperties\": False\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"name\": \"VectorDB_retriever\",\n",
    "        \"description\": \"\"\"BrokenPipeErrorUse this tool when the user's query involves general clinical or medical knowledge that is not tied to a specific patient.\n",
    "\n",
    "                This includes queries containing medical or procedural terms such as:\n",
    "                surgery names (e.g., \"cholecystectomy\", \"cardiac surgery\"), anesthesia types (e.g., \"general anesthesia\", \"local anesthesia\"), medications, clinical processes, or treatment guidelines.\n",
    "\n",
    "                Example queries:\n",
    "                - \"How does general anesthesia work?\"\n",
    "                - \"What are common complications of this surgery?\"\n",
    "                - \"What anesthetics are typically used in pediatric patients?\"\n",
    "\n",
    "                These types of queries are interpreted as requests for background medical knowledge or conceptual explanations. The tool retrieves semantically relevant information from a vector-based medical knowledge database.\n",
    "\n",
    "                Do not use this tool for patient-specific record queries or when structured relational data is needed, such as diagnosis timelines or surgical histories.\"\"\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"\"\"Construct a query that focuses on general medical or clinical knowledge, excluding any patient-specific details.\n",
    "\n",
    "                The query should be based on concepts extracted from the user's original question, such as surgery names, anesthesia types, diagnoses, medications, or treatment processes.\n",
    "\n",
    "                For example, if the user asks \"What kind of anesthesia was used for Kim's surgery?\", the query should be reformulated as \"What types of anesthesia are commonly used for that kind of surgery?\"\n",
    "\n",
    "                Avoid including patient names, identifiers, or individual medical histories. Focus on retrieving background information or typical medical explanations that are generally applicable.\"\"\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"query\"],\n",
    "            \"additionalProperties\": False\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_SYSTEM_PROMPTY = \"\"\"\n",
    "# INSTRUCTION\n",
    "ÎãπÏã†ÏùÄ ÏùòÎ£å Îç∞Ïù¥ÌÑ∞Ïóê ÌäπÌôîÎêú Ï†ÑÎ¨∏Í∞Ä AIÏûÖÎãàÎã§.\n",
    "ÏÇ¨Ïö©ÏûêÏùò ÏßàÎ¨∏Ïóê ÎåÄÌï¥ Îã§Ïùå Îëê Í∞ÄÏßÄ Ï∂úÏ≤òÏùò Ï†ïÎ≥¥Î•º Ï∞∏Í≥†ÌïòÏó¨ ÎãµÎ≥ÄÏùÑ ÏÉùÏÑ±ÌïòÏÑ∏Ïöî:\n",
    "\n",
    "1. üîé Neo4j Í≤ÄÏÉâ Í≤∞Í≥º: Íµ¨Ï°∞ÌôîÎêú ÌôòÏûê Í¥ÄÎ†® Ï†ïÎ≥¥ (Ïòà: ÏàòÏà† Ïù¥Î†•, Í≤ÄÏÇ¨ Í∏∞Î°ù Îì±)\n",
    "2. üìö VectorDB Í≤ÄÏÉâ Í≤∞Í≥º: ÏùºÎ∞òÏ†ÅÏù∏ ÏùòÌïô ÏßÄÏãù (Ïòà: Ï¶ùÏÉÅ ÏÑ§Î™Ö, ÏπòÎ£å Í∞ÄÏù¥ÎìúÎùºÏù∏ Îì±)\n",
    "\n",
    "- Îëê Í≤∞Í≥º Î™®Îëê Ï°¥Ïû¨Ìï† Í≤ΩÏö∞, Í∞Å Ï∂úÏ≤òÎ•º Íµ¨Î∂ÑÌïòÏó¨ ÌÜµÌï©Ï†ÅÏúºÎ°ú Î∞òÏòÅÌïòÎêò, Ï§ëÎ≥µ ÎÇ¥Ïö©ÏùÄ ÏöîÏïΩÌïòÍ±∞ÎÇò ÌÜµÌï©ÌïòÏÑ∏Ïöî.\n",
    "- Ìïú Ï™ΩÏùò Í≤∞Í≥ºÎßå Ï°¥Ïû¨Ìï† Í≤ΩÏö∞, Ìï¥Îãπ Í≤∞Í≥ºÎßåÏùÑ Î∞îÌÉïÏúºÎ°ú ÎãµÎ≥ÄÌïòÎêò, Ï†ïÎ≥¥Ïùò ÌïúÍ≥ÑÏóê ÎåÄÌï¥ Ïñ∏Í∏âÌïòÏßÄ ÎßêÍ≥† ÏµúÎåÄÌïú ÏÑ±Ïã§Ìûà ÎãµÎ≥ÄÌïòÏÑ∏Ïöî.\n",
    "- Í≤∞Í≥ºÍ∞Ä ÎÑàÎ¨¥ Ï†ÅÍ±∞ÎÇò Ïï†Îß§ÌïòÎçîÎùºÎèÑ Î∞òÎìúÏãú Ïú†ÏùòÎØ∏Ìïú ÏÑ§Î™ÖÏùÑ Ï†úÍ≥µÌïòÎ†§Í≥† ÎÖ∏Î†•ÌïòÏÑ∏Ïöî.\n",
    "- Î∂àÌïÑÏöîÌïú ÏÑúÎ°† ÏóÜÏù¥, ÏßàÎ¨∏Ïóê Î∞îÎ°ú ÎãµÎ≥ÄÌïòÏÑ∏Ïöî.\n",
    "\n",
    "# Neo4j CONTEXT\n",
    "{Neo4j}\n",
    "\n",
    "# Vector DB CONTEXT\n",
    "{VectorDB}\n",
    "\n",
    "# Question\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# LLM_REGENERATED_QUESTION = \"\"\"\n",
    "# You are a helpful assistant specialized in pediatric anesthesia. \n",
    "# You first think about the reasoning process in your mind and then rewrite the user‚Äôs question into a more effective form for document retrieval. \n",
    "# Your task is to convert user questions into concise, keyword-based queries suitable for sparse vector-based search in a pediatric anesthesia knowledge base.\n",
    "\n",
    "# Show your thought process in <think> </think> tags.  \n",
    "# Your final response must be in JSON format within <answer> </answer> tags.  \n",
    "# For example:  \n",
    "# <answer>  \n",
    "# {{  \n",
    "#   \"query\": \"...\"  \n",
    "# }}  \n",
    "# </answer>\n",
    "\n",
    "# Note: You may use Boolean operators (AND, OR) and parentheses when needed to group terms.\n",
    "\n",
    "# Here‚Äôs the user‚Äôs question related to pediatric anesthesia:  \n",
    "# {question}\n",
    "\n",
    "# Assistant: Let me think step by step.  \n",
    "# <think>\n",
    "# \"\"\"\n",
    "\n",
    "LLM_DECISION_SLACK = \"\"\"\n",
    "You are a decision-making assistant for Slack dispatch.\n",
    "If the user asks to send a message or question to a specific person via Slack (e.g., '~ÏóêÍ≤å Î≥¥ÎÇ¥Ï§ò', '~ÏóêÍ≤å Ï†ÑÏÜ°Ìï¥Ï§ò'),\n",
    "respond with \"Yes\".\n",
    "Otherwise, respond with \"No\".\n",
    "\n",
    "Only respond with \"Yes\" or \"No\". Do not include any explanation or formatting.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ResponseFunctionToolCall(arguments='{\"query\":\"AÌôòÏûê Ï†ïÎ≥¥ ÏïåÎ†§Ï§ò\"}', call_id='call_bYFRVMgTLp5Zsn4IvBqKKgam', name='neo4j_retriever', type='function_call', id='fc_68602cba820081a299158122efc8e342043d4b3d165b18d0', status='completed'), ResponseFunctionToolCall(arguments='{\"query\":\"Í∞êÍ∏∞Ïóê ÎåÄÌï¥ ÏïåÎ†§Ï§ò\"}', call_id='call_9HTmUVu93LJdBYryHvo5fjdU', name='VectorDB_retriever', type='function_call', id='fc_68602cba9d3881a29cd165a36bf0e5e9043d4b3d165b18d0', status='completed')]\n"
     ]
    }
   ],
   "source": [
    "# import json\n",
    "\n",
    "# question = \"AÌôòÏûê Ï†ïÎ≥¥ÏôÄ Í∞êÍ∏∞Ïóê ÎåÄÌï¥ÏÑú ÏïåÎ†§Ï§ò\"\n",
    "\n",
    "# input_messages = [\n",
    "#     {\"role\": \"system\", \"content\": \"Decide which tools to use to answer the user's question. You may call one or both.\"},\n",
    "#     {\"role\": \"user\", \"content\": question}\n",
    "# ]\n",
    "\n",
    "# response = model_client.responses.create(model=\"gpt-4.1\",\n",
    "#                                             input=input_messages,\n",
    "#                                             tools=tools)\n",
    "# print(response.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m input_text = LLM_REGENERATED_QUESTION.format(question = question)\n\u001b[32m      4\u001b[39m inputs = tokenizer(input_text, return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m).to(device)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m outputs = \u001b[43mdeepretrieval_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m response = tokenizer.decode(outputs[\u001b[32m0\u001b[39m], skip_special_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/boaz/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/boaz/lib/python3.11/site-packages/transformers/generation/utils.py:2465\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, **kwargs)\u001b[39m\n\u001b[32m   2457\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2458\u001b[39m         input_ids=input_ids,\n\u001b[32m   2459\u001b[39m         expand_size=generation_config.num_return_sequences,\n\u001b[32m   2460\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2461\u001b[39m         **model_kwargs,\n\u001b[32m   2462\u001b[39m     )\n\u001b[32m   2464\u001b[39m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2465\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2466\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2467\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2468\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2469\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2470\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2471\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2472\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2473\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2475\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2476\u001b[39m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[32m   2477\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2478\u001b[39m         input_ids=input_ids,\n\u001b[32m   2479\u001b[39m         expand_size=generation_config.num_beams,\n\u001b[32m   2480\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2481\u001b[39m         **model_kwargs,\n\u001b[32m   2482\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/boaz/lib/python3.11/site-packages/transformers/generation/utils.py:3476\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   3474\u001b[39m     probs = nn.functional.softmax(next_token_scores, dim=-\u001b[32m1\u001b[39m)\n\u001b[32m   3475\u001b[39m     \u001b[38;5;66;03m# TODO (joao): this OP throws \"skipping cudagraphs due to ['incompatible ops']\", find solution\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3476\u001b[39m     next_tokens = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmultinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m.squeeze(\u001b[32m1\u001b[39m)\n\u001b[32m   3477\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3478\u001b[39m     next_tokens = torch.argmax(next_token_scores, dim=-\u001b[32m1\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# question = \"Kasabach-Merrritt SyndromeÏù¥ Î≠êÏïº?\"\n",
    "\n",
    "# input_text = LLM_REGENERATED_QUESTION.format(question = question)\n",
    "# inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "# outputs = deepretrieval_model.generate(**inputs, \n",
    "#                             max_new_tokens=100,\n",
    "#                             temperature = 0.6)\n",
    "# response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'No'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from langchain.chat_models import ChatOpenAI\n",
    "# import re\n",
    "\n",
    "# model = ChatOpenAI(temperature=0.2, model_name=\"gpt-4o\")\n",
    "\n",
    "# LLM_DECISION_SLACK = \"\"\"\n",
    "# You are a decision-making assistant for Slack dispatch.\n",
    "# If the user asks to send a message or question to a specific person via Slack (e.g., '~ÏóêÍ≤å Î≥¥ÎÇ¥Ï§ò', '~ÏóêÍ≤å Ï†ÑÏÜ°Ìï¥Ï§ò'),\n",
    "# respond with \"yes\".\n",
    "# Otherwise, respond with \"no\".\n",
    "\n",
    "# Only respond with \"yes\" or \"no\". Do not include any explanation or formatting.\n",
    "# \"\"\"\n",
    "\n",
    "# SEND_COMMANDS = [\"Î≥¥ÎÇ¥Ï§ò\", \"Ï†ÑÏÜ°Ìï¥Ï§ò\"]\n",
    "\n",
    "# def determine_slack_usage(query: str) -> str:\n",
    "#     pattern = re.compile(r\"(.+?)ÏóêÍ≤å\\s*(.+?)\\s*(?:SlackÏúºÎ°ú\\s*)?(Î≥¥ÎÇ¥Ï§ò|Ï†ÑÏÜ°Ìï¥Ï§ò)\")\n",
    "#     m = pattern.search(query)\n",
    "#     return 'Yes' if m else 'No'\n",
    "\n",
    "# def decision_tools(question: str):\n",
    "#     user_query = question\n",
    "\n",
    "#     # 1) Rule-based ÌåêÎã®\n",
    "#     use_slack = determine_slack_usage(user_query)\n",
    "#     response = use_slack\n",
    "\n",
    "#     # 2) Î™ÖÌôïÌïòÏßÄ ÏïäÏùÄ Í≤ΩÏö∞ ‚Üí LLM ÌåêÎã®\n",
    "#     if use_slack == 'No' and (\"ÏóêÍ≤å\" in user_query or any(cmd in user_query for cmd in SEND_COMMANDS)):\n",
    "#         llm_response = model.invoke(f\"{LLM_DECISION_SLACK}\\n\\n{user_query}\")\n",
    "        \n",
    "#         response = llm_response\n",
    "#     print(response)\n",
    "#     return response\n",
    "\n",
    "# # ÌÖåÏä§Ìä∏\n",
    "# decision_tools(question=\"Ïú§ÏôïÍ∑ú Í∞ÑÌò∏ÏÇ¨ÌïúÌÖå 'hi' Î©îÏÑ∏ÏßÄ Ï†ÑÎã¨Ìï¥Ï§ò\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# SEND_COMMANDS = [\"Î≥¥ÎÇ¥Ï§ò\", \"Ï†ÑÏÜ°Ìï¥Ï§ò\", \"Ï†ÑÎã¨Ìï¥Ï§ò\"]\n",
    "\n",
    "# def determine_slack_usage(query: str) -> str:\n",
    "#     command_pattern = \"|\".join(SEND_COMMANDS)  \n",
    "#     pattern = re.compile(rf\"(.+?)ÏóêÍ≤å\\s*(.+?)\\s*(?:SlackÏúºÎ°ú\\s*)?({command_pattern})\")\n",
    "#     m = pattern.search(query)\n",
    "#     return 'Yes' if m else 'No'\n",
    "\n",
    "# def determine_slack_usage(query: str) -> str:\n",
    "#     return 'Yes' if any(cmd in query for cmd in SEND_COMMANDS) else 'No'\n",
    "\n",
    "# async def decision_slack(state: ChatbotState):\n",
    "#     user_query = state[\"question\"]\n",
    "\n",
    "#     # 1) Rule-based ÌåêÎã®\n",
    "#     use_slack = determine_slack_usage(user_query)\n",
    "#     response = use_slack  # Í∏∞Î≥∏Í∞í ÏÑ§Ï†ï\n",
    "\n",
    "#     # 2) Ìå®ÌÑ¥ÏùÄ ÏùºÎ∂Ä ÏûàÏßÄÎßå Î™ÖÌôïÌïòÏßÄ ÏïäÏùÄ Í≤ΩÏö∞ ‚Üí LLM ÌåêÎã®\n",
    "#     if use_slack.lower() == 'no' and (\"ÏóêÍ≤å\" in user_query or any(cmd in user_query for cmd in SEND_COMMANDS)):\n",
    "#         llm_response = await model.ainvoke(f\"{LLM_DECISION_SLACK}\\n\\n{user_query}\")\n",
    "#         response = llm_response\n",
    "\n",
    "#     return ChatbotState(decision_slack=response)\n",
    "\n",
    "async def decision_tools(state: ChatbotState):\n",
    "    \n",
    "    question = state[\"question\"]\n",
    "\n",
    "    input_messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Decide which tools to use to answer the user's question. You may call one or both.\"},\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    "    \n",
    "    response = model_client.responses.create(model=\"gpt-4.1\",\n",
    "                                             input=input_messages,\n",
    "                                             tools=function_calling_tools)\n",
    "    \n",
    "    tools_name = [tool.name for tool in response.output]\n",
    "    tools_query = [json.loads(call.arguments)[\"query\"] for call in response.output]\n",
    "\n",
    "    return ChatbotState(tools=tools_name,\n",
    "                        tools_query=tools_query)\n",
    "\n",
    "async def neo4j_to_vectordb(state: ChatbotState):\n",
    "    \"\"\"\n",
    "    ‚ë† Neo4j ‚Üí ‚ë° VectorDB ÏàúÏÑúÎ°ú Ìò∏Ï∂úÌïòÍ≥†\n",
    "    Îëê Í≤∞Í≥ºÎ•º Î™®Îëê stateÏóê Ï†ÄÏû•.\n",
    "    \"\"\"\n",
    "    # ---- ‚ë† Neo4j -------------------------------------------------\n",
    "    question = next(\n",
    "        q for t, q in zip(state[\"tools\"], state[\"tools_query\"])\n",
    "        if t == \"neo4j_retriever\"\n",
    "    )\n",
    "\n",
    "    neo4j_tool = tools_dict[\"neo4j_retriever\"]\n",
    "    neo_res = await neo4j_tool.ainvoke({\"question\": question, \"top_k\": 3})\n",
    "\n",
    "    # ---- ‚ë° VectorDB (Neo4j Í≤∞Í≥ºÎ°ú ÏøºÎ¶¨ ÌôïÏû•) ----------------------\n",
    "    vec_tool  = tools_dict[\"VectorDB_retriever\"]\n",
    "    expanded_query = f\"{question}\\n\\nGRAPH_CONTEXT:\\n{neo_res}\"\n",
    "    vec_res = await vec_tool.ainvoke({\"query\": expanded_query, \"top_k\": 5})\n",
    "\n",
    "    # LangGraphÎäî ‚ÄúÎ∂ÄÎ∂Ñ ÎîïÏÖîÎÑàÎ¶¨‚ÄùÎßå ÎèåÎ†§Ï£ºÎ©¥ Í∏∞Ï°¥ stateÏôÄ merge\n",
    "    return ChatbotState(neo4j_documents = neo_res, \n",
    "                        vector_documents = vec_res)\n",
    "\n",
    "async def vector_db(state: ChatbotState):\n",
    "    question = None\n",
    "    for tool, q in zip(state[\"tools\"], state[\"tools_query\"]):\n",
    "        if tool == \"VectorDB_retriever\":\n",
    "            question = q\n",
    "            break\n",
    "\n",
    "    # ÏßàÎ¨∏ Ïû¨ÏÉùÏÑ±\n",
    "    # input_text = LLM_REGENERATED_QUESTION.format(question = question)\n",
    "    # inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "    # outputs = model.generate(**inputs, \n",
    "    #                          max_new_tokens=500,\n",
    "    #                          temperature = 0.6)\n",
    "    # response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            \n",
    "    vectordb_tool = tools_dict[\"VectorDB_retriever\"]\n",
    "        \n",
    "    result = await vectordb_tool.ainvoke({\"query\": question})\n",
    "\n",
    "    return ChatbotState(vector_documents=result,\n",
    "                        # regenerated_question=response\n",
    "                        )\n",
    "\n",
    "async def neo4j_db(state: ChatbotState):\n",
    "    question = None\n",
    "    for tool, q in zip(state[\"tools\"], state[\"tools_query\"]):\n",
    "        if tool == \"neo4j_retriever\":\n",
    "            question = q\n",
    "            break\n",
    "    \n",
    "    neo4j_tool = tools_dict.get(\"neo4j_retriever\")\n",
    "    \n",
    "    # result = await neo4j_tool.ainvoke({\"query\": question})\n",
    "    result = await neo4j_tool.ainvoke({\n",
    "        \"question\": question,   # ‚Üê ÌïÑÏàò\n",
    "        \"top_k\": 3              # ‚Üê ÏÉùÎûµ Í∞ÄÎä•, Í∏∞Î≥∏ 3\n",
    "    })\n",
    "\n",
    "    return ChatbotState(neo4j_documents=result)\n",
    "\n",
    "# Ïó¨Í∏∞ÏÑú ÏßàÎ¨∏ + Í≤ÄÏÉâ Î¨∏ÏÑú ÎÑ£Í≥† ÏòàÏÅòÍ≤å ÌîÑÎ°¨ÌîÑÌä∏\n",
    "async def merge_outputs(state:ChatbotState):\n",
    "\n",
    "    question = state['question']\n",
    "    vector_documents = state['vector_documents']\n",
    "    neo4j_documents = state['neo4j_documents']\n",
    "\n",
    "    slack_state = state['decision_slack']\n",
    "\n",
    "    formatted = LLM_SYSTEM_PROMPTY.format(Neo4j = neo4j_documents,\n",
    "                                          VectorDB = vector_documents,\n",
    "                                          question = question)\n",
    "    response = await model.ainvoke(formatted)\n",
    "    final_response_text = response.content if isinstance(response, AIMessage) else str(response)\n",
    "\n",
    "    # ÏúÑÏóêÏÑú slack Î≥¥ÎÉÑ Ïó¨Î∂ÄÍ∞Ä 'Yes'Ïù¥Î©¥ LLM ÏµúÏ¢Ö ÎãµÎ≥ÄÏùÑ SlackÏúºÎ°ú Î≥¥ÎÇ¥Í∏∞\n",
    "    if slack_state.lower() == 'yes':\n",
    "        tools = await mcp_client.get_tools()\n",
    "        agent = create_react_agent(model, tools)\n",
    "        content = f\"Î∞±ÏßÄÏó∞Ïù¥ ÏÜçÌï¥ ÏûàÎäî Ï±ÑÎÑêÏóê {final_response_text} Î≥¥ÎÇ¥Ï§ò. slack_post_message Ìà¥ÏùÑ Ïç®.\"\n",
    "        slack_response = await agent.ainvoke({\"messages\": [{\"role\": \"user\",\n",
    "                                                    \"content\": content}]})                                                                                                                                                                       \n",
    "    return ChatbotState(final_answer=final_response_text,\n",
    "                        # slack_response=slack_response,\n",
    "                        messages=[(\"user\", question), (\"assistant\", final_response_text)])\n",
    "\n",
    "# async def join_node(state: ChatbotState):\n",
    "#     return state  # Îã®ÏàúÌûà Í≤∞Í≥ºÎßå Î™®ÏïÑÏÑú ÎÑòÍπÄ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x30f3d8f90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder = StateGraph(ChatbotState)\n",
    "\n",
    "# builder.add_node(\"slack\", decision_slack)\n",
    "builder.add_node(\"decision_tools\", decision_tools)\n",
    "builder.add_node(\"neo4j_to_vectordb\", neo4j_to_vectordb)\n",
    "# builder.add_node(\"join_node\", join_node)\n",
    "builder.add_node(\"vector_db\", vector_db)\n",
    "builder.add_node(\"neo4j_db\", neo4j_db)\n",
    "builder.add_node(\"merge_outputs\", merge_outputs)\n",
    "\n",
    "builder.add_edge(START, \"decision_tools\")\n",
    "# builder.add_edge(START, \"slack\")\n",
    "\n",
    "# builder.add_edge(\"slack\", \"join_node\")\n",
    "# builder.add_edge(\"decision_tools\", \"join_node\")\n",
    "\n",
    "def route_tools(state: ChatbotState):\n",
    "    return state[\"tools\"]\n",
    "\n",
    "# builder.add_conditional_edges(\n",
    "#     \"decision_tools\",\n",
    "#     route_tools,\n",
    "#     {\n",
    "#         \"neo4j_retriever\": \"neo4j_db\",\n",
    "#         \"VectorDB_retriever\": \"vector_db\"\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# builder.add_conditional_edges(\n",
    "#     \"join_node\",\n",
    "#     route_tools,\n",
    "#     {\n",
    "#         \"neo4j_retriever\": \"neo4j_db\",\n",
    "#         \"VectorDB_retriever\": \"vector_db\"\n",
    "#     }\n",
    "# )\n",
    "\n",
    "builder.add_edge(\"decision_tools\",\"neo4j_db\")\n",
    "builder.add_edge(\"decision_tools\",\"vector_db\")\n",
    "builder.add_edge(\"decision_tools\",\"neo4j_to_vectordb\")\n",
    "builder.add_edge(\"neo4j_db\", \"merge_outputs\")\n",
    "builder.add_edge(\"vector_db\", \"merge_outputs\")\n",
    "builder.add_edge(\"neo4j_to_vectordb\", \"merge_outputs\")\n",
    "builder.add_edge(\"merge_outputs\", END)\n",
    "\n",
    "builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'decision_tools': {'tools': ['neo4j_retriever'], 'tools_query': ['Ïò§Î•∏ÏÜê Ìï©ÏßÄÏ¶ù Î∂ÑÎ¶¨Ïà† ÏàòÏà†ÏùÑ Î∞õÏùÄ ÏÇ¨ÎûåÏùò Ïù¥Î¶ÑÏùÑ ÏïåÎ†§Ï§ò.']}}\n",
      "{'slack': {'decision_slack': 'Yes'}}\n",
      "{'join_node': {'question': 'Ïò§Î•∏ÏÜê Ìï©ÏßÄÏ¶ù Î∂ÑÎ¶¨Ïà† ÏàòÏà†ÏùÑ Î∞õÏùÄ ÏÇ¨ÎûåÏùò Ïù¥Î¶ÑÏùÑ Ï∞æÍ≥† slackÏúºÎ°ú Ï†ÑÎã¨Ìï¥Ï§ò.', 'decision_slack': 'Yes', 'tools': ['neo4j_retriever'], 'tools_query': ['Ïò§Î•∏ÏÜê Ìï©ÏßÄÏ¶ù Î∂ÑÎ¶¨Ïà† ÏàòÏà†ÏùÑ Î∞õÏùÄ ÏÇ¨ÎûåÏùò Ïù¥Î¶ÑÏùÑ ÏïåÎ†§Ï§ò.'], 'neo4j_documents': [], 'vector_documents': [], 'final_answer': '', 'slack_response': '', 'messages': []}}\n"
     ]
    },
    {
     "ename": "ToolException",
     "evalue": "Error executing tool neo4j_retriever: {code: Neo.ClientError.Procedure.ProcedureNotFound} {message: There is no procedure with the name `db.vector.similarity.matchNodes` registered for this database instance. Please ensure you've spelled the procedure name correctly and that the procedure is properly deployed.}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mToolException\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     10\u001b[39m initial_state = {\n\u001b[32m     11\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m: question,\n\u001b[32m     12\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdecision_slack\u001b[39m\u001b[33m\"\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     19\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [],\n\u001b[32m     20\u001b[39m }\n\u001b[32m     22\u001b[39m events = []\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m graph.astream(initial_state, config=config):\n\u001b[32m     24\u001b[39m     \u001b[38;5;28mprint\u001b[39m(event)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/boaz/lib/python3.11/site-packages/langgraph/pregel/__init__.py:2759\u001b[39m, in \u001b[36mPregel.astream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2753\u001b[39m \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[32m   2754\u001b[39m \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[32m   2755\u001b[39m \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[32m   2756\u001b[39m \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[32m   2757\u001b[39m \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[32m   2758\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m loop.tick(input_keys=\u001b[38;5;28mself\u001b[39m.input_channels):\n\u001b[32m-> \u001b[39m\u001b[32m2759\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner.atick(\n\u001b[32m   2760\u001b[39m         loop.tasks.values(),\n\u001b[32m   2761\u001b[39m         timeout=\u001b[38;5;28mself\u001b[39m.step_timeout,\n\u001b[32m   2762\u001b[39m         retry_policy=\u001b[38;5;28mself\u001b[39m.retry_policy,\n\u001b[32m   2763\u001b[39m         get_waiter=get_waiter,\n\u001b[32m   2764\u001b[39m     ):\n\u001b[32m   2765\u001b[39m         \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[32m   2766\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m output():\n\u001b[32m   2767\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m o\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 82\u001b[39m, in \u001b[36mneo4j_db\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     79\u001b[39m neo4j_tool = tools_dict.get(\u001b[33m\"\u001b[39m\u001b[33mneo4j_retriever\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     81\u001b[39m \u001b[38;5;66;03m# result = await neo4j_tool.ainvoke({\"query\": question})\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m neo4j_tool.ainvoke({\n\u001b[32m     83\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m: question,   \u001b[38;5;66;03m# ‚Üê ÌïÑÏàò\u001b[39;00m\n\u001b[32m     84\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtop_k\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m3\u001b[39m              \u001b[38;5;66;03m# ‚Üê ÏÉùÎûµ Í∞ÄÎä•, Í∏∞Î≥∏ 3\u001b[39;00m\n\u001b[32m     85\u001b[39m })\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ChatbotState(neo4j_documents=result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/boaz/lib/python3.11/site-packages/langchain_core/tools/structured.py:66\u001b[39m, in \u001b[36mStructuredTool.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.coroutine:\n\u001b[32m     63\u001b[39m     \u001b[38;5;66;03m# If the tool does not implement async, fall back to default implementation\u001b[39;00m\n\u001b[32m     64\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m run_in_executor(config, \u001b[38;5;28mself\u001b[39m.invoke, \u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().ainvoke(\u001b[38;5;28minput\u001b[39m, config, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/boaz/lib/python3.11/site-packages/langchain_core/tools/base.py:523\u001b[39m, in \u001b[36mBaseTool.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    515\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    516\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mainvoke\u001b[39m(\n\u001b[32m    517\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    520\u001b[39m     **kwargs: Any,\n\u001b[32m    521\u001b[39m ) -> Any:\n\u001b[32m    522\u001b[39m     tool_input, kwargs = _prep_run_args(\u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m523\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.arun(tool_input, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/boaz/lib/python3.11/site-packages/langchain_core/tools/base.py:887\u001b[39m, in \u001b[36mBaseTool.arun\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    885\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_to_raise:\n\u001b[32m    886\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m run_manager.on_tool_error(error_to_raise)\n\u001b[32m--> \u001b[39m\u001b[32m887\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_to_raise\n\u001b[32m    889\u001b[39m output = _format_output(content, artifact, tool_call_id, \u001b[38;5;28mself\u001b[39m.name, status)\n\u001b[32m    890\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m run_manager.on_tool_end(output, color=color, name=\u001b[38;5;28mself\u001b[39m.name, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/boaz/lib/python3.11/site-packages/langchain_core/tools/base.py:856\u001b[39m, in \u001b[36mBaseTool.arun\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    853\u001b[39m         tool_kwargs[config_param] = config\n\u001b[32m    855\u001b[39m     coro = \u001b[38;5;28mself\u001b[39m._arun(*tool_args, **tool_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m856\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m coro_with_context(coro, context)\n\u001b[32m    857\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.response_format == \u001b[33m\"\u001b[39m\u001b[33mcontent_and_artifact\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    858\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(response) != \u001b[32m2\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/boaz/lib/python3.11/site-packages/langchain_core/tools/structured.py:110\u001b[39m, in \u001b[36mStructuredTool._arun\u001b[39m\u001b[34m(self, config, run_manager, *args, **kwargs)\u001b[39m\n\u001b[32m    108\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m config_param := _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m.coroutine):\n\u001b[32m    109\u001b[39m         kwargs[config_param] = config\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.coroutine(*args, **kwargs)\n\u001b[32m    112\u001b[39m \u001b[38;5;66;03m# If self.coroutine is None, then this will delegate to the default\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[38;5;66;03m# implementation which is expected to delegate to _run on a separate thread.\u001b[39;00m\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()._arun(\n\u001b[32m    115\u001b[39m     *args, config=config, run_manager=run_manager, **kwargs\n\u001b[32m    116\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/boaz/lib/python3.11/site-packages/langchain_mcp_adapters/tools.py:105\u001b[39m, in \u001b[36mconvert_mcp_tool_to_langchain_tool.<locals>.call_tool\u001b[39m\u001b[34m(**arguments)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    104\u001b[39m     call_tool_result = \u001b[38;5;28;01mawait\u001b[39;00m session.call_tool(tool.name, arguments)\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert_call_tool_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall_tool_result\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/boaz/lib/python3.11/site-packages/langchain_mcp_adapters/tools.py:43\u001b[39m, in \u001b[36m_convert_call_tool_result\u001b[39m\u001b[34m(call_tool_result)\u001b[39m\n\u001b[32m     40\u001b[39m     tool_content = tool_content[\u001b[32m0\u001b[39m]\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m call_tool_result.isError:\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ToolException(tool_content)\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tool_content, non_text_contents \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mToolException\u001b[39m: Error executing tool neo4j_retriever: {code: Neo.ClientError.Procedure.ProcedureNotFound} {message: There is no procedure with the name `db.vector.similarity.matchNodes` registered for this database instance. Please ensure you've spelled the procedure name correctly and that the procedure is properly deployed.}",
      "During task with name 'neo4j_db' and id '7bbfa055-34ba-0beb-9f49-69aa3cfcb301'"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "config = RunnableConfig(configurable={\"thread_id\": 1})\n",
    "\n",
    "# question = \"Kasabach-Merrritt SyndromeÏóê ÎåÄÌï¥ÏÑú Ï°∞ÏÇ¨ÌïòÍ≥† slackÏúºÎ°ú Ï†ÑÎã¨Ìï¥Ï§ò.\"\n",
    "question = \"Ïò§Î•∏ÏÜê Ìï©ÏßÄÏ¶ù Î∂ÑÎ¶¨Ïà† ÏàòÏà†ÏùÑ Î∞õÏùÄ ÏÇ¨ÎûåÏùò Ïù¥Î¶ÑÏùÑ Ï∞æÍ≥† slackÏúºÎ°ú Ï†ÑÎã¨Ìï¥Ï§ò.\"\n",
    "\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "\n",
    "initial_state = {\n",
    "    \"question\": question,\n",
    "    \"decision_slack\":\"\",\n",
    "    \"tools\": [],\n",
    "    \"tools_query\" : [],\n",
    "    \"neo4j_documents\": [],\n",
    "    \"vector_documents\": [],\n",
    "    \"final_answer\": \"\",\n",
    "    \"slack_response\":\"\",\n",
    "    \"messages\": [],\n",
    "}\n",
    "\n",
    "events = []\n",
    "async for event in graph.astream(initial_state, config=config):\n",
    "    print(event)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boaz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
