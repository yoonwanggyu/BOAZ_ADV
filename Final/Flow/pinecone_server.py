from dotenv import load_dotenv
from langchain_openai import OpenAIEmbeddings
from langchain.retrievers import ContextualCompressionRetriever
from langchain.retrievers.document_compressors import CrossEncoderReranker
from langchain_community.cross_encoders import HuggingFaceCrossEncoder
from mcp.server.fastmcp import FastMCP
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_pinecone import PineconeVectorStore
import os
from pinecone import Pinecone

load_dotenv("/Users/yoon/BOAZ_ADV/Wang_Gyu/code/mcp/.env")

openai_api_key = os.environ["OPENAI_API_KEY"]
pinecone_api_key = os.environ["PINECONE_API_KEY"]
pinecone_index_name = "boazpubmed"

def create_retriever():
    # ì„ë² ë”© ëª¨ë¸
    embeddings = OpenAIEmbeddings(
        model="text-embedding-ada-002",
        api_key=openai_api_key
    )

    # Pinecone í´ë¼ì´ì–¸íŠ¸ ë° ì¸ë±ìŠ¤ ë¡œë“œ
    pc = Pinecone(api_key=pinecone_api_key)
    index = pc.Index(pinecone_index_name)

    # LangChain VectorStoreë¡œ ë˜í•‘
    vectorstore = PineconeVectorStore(
        index=index,
        embedding=embeddings,
        text_key="page_content"
    )

    # CrossEncoder reranker ì„¤ì •
    reranker_model = HuggingFaceCrossEncoder(model_name="BAAI/bge-reranker-v2-m3")
    compressor_retriever = CrossEncoderReranker(
        model=reranker_model,
        top_n=5
    )

    # ê¸°ë³¸ ê²€ìƒ‰ê¸° â†’ ì••ì¶•ëœ Retrieverë¡œ ê°ì‹¸ê¸°
    base_retriever = vectorstore.as_retriever(search_kwargs={"k": 10})
    retriever = ContextualCompressionRetriever(
        base_retriever=base_retriever,
        base_compressor=compressor_retriever
    )

    return retriever

# MCP ì„œë²„ ì •ì˜
mcp = FastMCP(
    "VectorDB_Retriever",
    instructions="A Retriever that can retrieve information from the Pinecone VectorDB.",
    host="0.0.0.0",
    port=8005
)

# MCP tool í•¨ìˆ˜ ì •ì˜
@mcp.tool()
async def VectorDB_retriever(query: str):
    retriever = create_retriever()
    retrieved_docs = retriever.invoke(query)
    return "\n".join([doc.page_content for doc in retrieved_docs])

# ì‹¤í–‰
if __name__ == "__main__":
    print("ğŸ“¡ MCP server is running on port 8005...")
    mcp.run(transport="stdio")

# load_dotenv()

# def create_retriever():
    
#     # 1536ì°¨ì› ì„ë² ë”© ì‚¬ìš© (ì¸ë±ìŠ¤ì™€ ì¼ì¹˜)
#     embeddings = OpenAIEmbeddings(model="text-embedding-ada-002",
#                                   api_key=os.getenv("OPENAI_API_KEY"))
    
#     # ì˜¬ë°”ë¥¸ ì„¤ì •
#     pinecone_vs = PineconeVectorStore.from_existing_index(
#         index_name="boazpubmed",
#         embedding=embeddings,
#         namespace="",  # ë¹ˆ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ (26483ê°œ ë¬¸ì„œê°€ ìˆëŠ” ê³³)
#         text_key="page_content"  # ğŸ¯ í•µì‹¬: ì‹¤ì œ í…ìŠ¤íŠ¸ê°€ ì €ì¥ëœ í‚¤
#     )

#     # Reranker ì„¤ì •
#     reranker = HuggingFaceCrossEncoder(model_name="ncbi/MedCPT-Cross-Encoder") #MedCPT-Cross-Encoder ë¦¬ë­ì»¤ ì‚¬ìš©ìš©
#     compressor = CrossEncoderReranker(model=reranker, top_n=4)

#     base = pinecone_vs.as_retriever(search_kwargs={"k": 10})
#     compression_retriever = ContextualCompressionRetriever(
#         base_retriever=base,
#         base_compressor=compressor)
    
#     return compression_retriever

# mcp = FastMCP(
#     "VectorDB_Retriever",
#     instructions="A Retriever that can retrieve information from the Chroma VectorDB.",
#     host="0.0.0.0",
#     port=8005
# )

# @mcp.tool()
# async def VectorDB_retriever(query: str):

#     retriever = create_retriever()

#     return retriever

# if __name__ == "__main__":
#     mcp.run(transport="stdio")