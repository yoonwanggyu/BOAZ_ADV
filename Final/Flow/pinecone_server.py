from dotenv import load_dotenv
from langchain_openai import OpenAIEmbeddings
from langchain.retrievers import ContextualCompressionRetriever
from langchain.retrievers.document_compressors import CrossEncoderReranker
from langchain_community.cross_encoders import HuggingFaceCrossEncoder
from mcp.server.fastmcp import FastMCP
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_pinecone import PineconeVectorStore
import os

load_dotenv()

def create_retriever():
    
    # 1536ì°¨ì› ì„ë² ë”© ì‚¬ìš© (ì¸ë±ìŠ¤ì™€ ì¼ì¹˜)
    embeddings = OpenAIEmbeddings(model="text-embedding-ada-002",
                                  api_key=os.getenv("OPENAI_API_KEY"))
    
    # ì˜¬ë°”ë¥¸ ì„¤ì •
    pinecone_vs = PineconeVectorStore.from_existing_index(
        index_name="boazpubmed",
        embedding=embeddings,
        namespace="",  # ë¹ˆ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ (26483ê°œ ë¬¸ì„œê°€ ìˆëŠ” ê³³)
        text_key="page_content"  # ğŸ¯ í•µì‹¬: ì‹¤ì œ í…ìŠ¤íŠ¸ê°€ ì €ì¥ëœ í‚¤
    )

    # Reranker ì„¤ì •
    reranker = HuggingFaceCrossEncoder(model_name="ncbi/MedCPT-Cross-Encoder") #MedCPT-Cross-Encoder ë¦¬ë­ì»¤ ì‚¬ìš©ìš©
    compressor = CrossEncoderReranker(model=reranker, top_n=4)

    base = pinecone_vs.as_retriever(search_kwargs={"k": 10})
    compression_retriever = ContextualCompressionRetriever(
        base_retriever=base,
        base_compressor=compressor)
    
    return compression_retriever

mcp = FastMCP(
    "VectorDB_Retriever",
    instructions="A Retriever that can retrieve information from the Chroma VectorDB.",
    host="0.0.0.0",
    port=8005
)

@mcp.tool()
async def VectorDB_retriever(query: str):

    retriever = create_retriever()

    return retriever

if __name__ == "__main__":
    mcp.run(transport="stdio")